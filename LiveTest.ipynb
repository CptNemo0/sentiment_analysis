{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999deb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import my_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7be04d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d4fbaae410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONSTS\n",
    "MAX_SEQ_LEN    = 400\n",
    "DEVICE         = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "SEED           = 25072023\n",
    "NUM_EMBEDDINGS = 100264\n",
    "EMBEDDING_DIM  = 1024\n",
    "HIDDEN_SIZE    = 512\n",
    "NUM_LAYERS     = 2        \n",
    "LABELS         = 2\n",
    "PARAMS_FILE    = \"network_params_1.params\"\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a627892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(selected_data):\n",
    "        encoded_data = []\n",
    "        encoder = tiktoken.get_encoding(\"cl100k_base\") #gpt4\n",
    "        for sd in selected_data:\n",
    "            encoded_data.append(encoder.encode(sd))\n",
    "            \n",
    "        truncated_data = []\n",
    "        for e in encoded_data:\n",
    "            if len(e) < MAX_SEQ_LEN:\n",
    "                to_add = MAX_SEQ_LEN - len(e)\n",
    "                for i in range(to_add):\n",
    "                    e.append(220)\n",
    "                truncated_data.append(e)\n",
    "            if len(e) > MAX_SEQ_LEN:\n",
    "                truncated_data.append(e[:MAX_SEQ_LEN])\n",
    "        return truncated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd60261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(100264, 1024)\n",
       "  (lstm): LSTM(1024, 512)\n",
       "  (lin): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_classes.Net(NUM_EMBEDDINGS, EMBEDDING_DIM, HIDDEN_SIZE, LABELS)\n",
    "model.load_state_dict(torch.load(PARAMS_FILE))\n",
    "model.eval()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539219ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''\n",
    "\n",
    "I'm still collecting my thoughts after experiencing this film, Cillian Murphy might as well start clearing a space on his mantle for the Best Actor Oscar.\n",
    "\n",
    "This film is a masterclass in weaving narratives and different time periods while exploring the profound depths of a man whose actions altered the world's trajectory forever, for better or worse. Nolan brings us into the complexities of Oppenheimer, and all the moral conflicts stirring within him.\n",
    "\n",
    "Murphy's portrayal is so riveting that the long run-time became an afterthought. Robert Downey Jr also offers a great performance and Nolan's push and pull with how he uses sound design throughout is the cherry on top.\n",
    "\n",
    "Some viewers might need a brief refresher on WWII and Cold War history, but any film lover should be happy to willingly lose themselves in this film for hours on end.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21262467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    selected_data = [test]\n",
    "    encoded_data = encode_data(selected_data)\n",
    "    inputs = np.array(encoded_data).astype('float32')\n",
    "    inputs = torch.tensor(inputs)\n",
    "    inputs = inputs.type(torch.int)\n",
    "    inputs  = inputs.to(DEVICE)\n",
    "    inputs = inputs.T\n",
    "    logits = model(inputs)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    idx = torch.argmax(probs)\n",
    "    if(idx.item() == 0):\n",
    "        print(\"negative\")\n",
    "    else:\n",
    "        print(\"positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
